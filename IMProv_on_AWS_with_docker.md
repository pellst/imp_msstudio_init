# IMProv ( integrative modeling platform ) - Workflow (0.1)

This tutorial presents the step by step instructions to gather the data files 
and driver scripts needed to perform a [MPI based IMP modeling](https://integrativemodeling.org/) job run. We demonstrate
these steps using the [PRC2 example project](https://github.com/pellst/imp_msstudio_init/tree/master/mss_out) and explain how this was prepared 
using [MassSpecStudio](https://www.msstudio.ca/mss-improv/). The instructions cover running the job on AWS platform, using a docker image:

* AWS: EC2 spot instance


#### PRC2 example project:  
* view imp_msstudio_init [on github, here.](https://github.com/pellst/imp_msstudio_init/tree/master/mss_out)
* then, download PRC2 example project, [here.](https://github.com/pellst/imp_msstudio_init/archive/master.zip)

Folders and files included in this project:
* **data**
   * em
   * fasta
   * hx
   * topo
   * xl
   * xtal  
* **imp_model**
   * aws_run_onenode.sh
   * ConfigImp.yaml
   * prep_hyper_imp_v2ux.py
   * ... and others 

The **data** folder contains various artifacts used to inform the integrative modeling.
The **imp_model** folder contains the driver python script and example yaml configuration for running the IMP modeling job.




IMProv Job Run: 
![alt text](https://github.com/pellst/imp_msstudio_init/raw/master/IMProv_uml_diag.png "Logo Title Text 1")

MassSpecStudio: 
![alt text][logo]

[logo]: https://github.com/pellst/imp_msstudio_init/raw/master/uml_diag_IMProv_msstudio.png "msstudio IMProv prep"



## Getting Started

These instructions will get you a copy of the example project up and running for testing purposes. 
* how to setup new instance with python (3.x) and imp packages, together with sample project for PRC2.
  * initial run for modeling 200 frames ( approx. run duration is 10min ).
  * how to deploy the project on a live system for a short run. 
    * **runbook** for steps to setup software and data/driver scripts.
    * **playbook** for troubleshooting issues.






**AWS job run**

* this requires running EC2 instances that are not eligible for the AWS Free Tier. While pricing varies, the typical cost for a 32cpu machine is under USD1.00 per hour.
* links to AWS account setup, default VPC launch of EC2 instance using either on-demand or spot instance.
* cloudcraft diagram of VPC, subnet, EC2 instance ( 16, 32 cpu options) , pricing ( on-demand, spot )
* cloudformation script
* prep AMI based on parallel-cluster image ( give version num ) - snapshot for golden image
* Amendment of cloudcraft script ( json or yaml style ) add AMI golden image to use
* IAM role for s3 upload of modeling results. 
  * TODO: add scripted copy of modeling output data to s3.
* option to upload a project content to s3 to store the project bundle generated by msstudio.
* 




#### docker image: 

Once we have launched the Amazon Linux EC2 and logged in as ec2-user. We can perform the following steps
* install docker
* get the docker image
* run the docker container
* login to the docker container 
* setup the sample project and amend scripts


**steps to install docker**
```
sudo yum update -y
# install docker 
sudo amazon-linux-extras install docker
# start docker service
sudo service docker start
# setup ec2-user permissions
sudo usermod -a -G docker ec2-user
# setup docker to restart after reboot
sudo systemctl enable docker
# logout and log back in for permissions to take
exit

# log back in as ec2-user
# confirm docker available 
docker info


```

for docker image: pellst/anaimp:anaimpv010
* Anaconda Version : https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh 
* Python Version: 3.7
* IMP Version : imp_2_14_0


**steps to pull docker image**
```
docker login
# provide your own docker credentials username and password
docker pull pellst/anaimp:anaimpv010

#Digest: sha256:b27a3afbb873ac1612be7d5508ac4af06e390d309aaf1b03374bf71e691904fb
#Status: Downloaded newer image for pellst/anaimp:anaimpv010
#docker.io/pellst/anaimp:anaimpv010

# list the docker images
docker images

#REPOSITORY      TAG          IMAGE ID       CREATED         SIZE
#pellst/anaimp   anaimpv010   13dd48a06af4   16 months ago   11.7GB


# we have /shared/notebooks mapped to /home/ubuntu/notebooks
# we can make file and script changes outside the container such that these are seen in the notebooks folder inside the container
# use the image id at the end; -d means detached 

#sudo mkdir /shared
#sudo chmod
cd /shared
docker run --name anaimp -p 8888:8888 --env="DISPLAY"       -v "$PWD/notebooks:/home/ubuntu/notebooks" -d 13dd48a06af4

docker container ls -a

#CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS                     PORTS                                       NAMES
#a848d063379e   13dd48a06af4   "jupyter notebook --…"   2 minutes ago   Up 2 minutes               0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   anaimp






```



**View from inside docker container that is running**
```
#login to container to interactive script running
# container ID is found from previous listing
docker exec -it a848d063379e bash
#the prompt is now inside the container
ls -ltr

#ubuntu
sudo apt-get update
sudo apt-get -y install curl
sudo apt-get -y install vim

# already setup in docker image
#sudo ln -s /home/ubuntu/shared /
#sudo ln -s /home/ubuntu/anaconda3 /shared/anaconda

#then you can 
cd /home/ubuntu/notebooks 
# add the aws_mss_prep_step1.sh, given below
#and run the 
./aws_mss_prep_step1.sh
# this prepares the modelling folder and scripts for a test run

```





**View from EC2 machine**
```
#Login to the EC2 machine, with an additional session, as ec2-user
cd /shared/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model
# now the scripts can be amended such that the change is seen by the container


```




**Content of aws_mss_prep_step1.sh for docker version**
```
#!/bin/bash
# from the /home/ubuntu/notebooks
#sudo su -
cd /home/ubuntu/notebooks
mkdir imp
cd imp
# get the demo imp job to test a job run
curl -LOk https://github.com/pellst/imp_msstudio_init/archive/master.zip
unzip master.zip
sudo chmod 777 /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/*
#cd /shared/imp/imp_msstudio_init-master/mss_out/imp_model
cd /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model
#chmod 755 /shared/imp/imp_msstudio_init-master/mss_out/imp_model/aws_mss_prep_step*
chmod 755 /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model/aws*


```




**Content of ConfigImp.yaml for testing**
```
title: PRC2 with HX and EM
date: 2019-07-10T12:10:31.1913934-06:00
cores: 8 
replicates: 1
states: 1
sampling_frame: 20
output_dir: ./imp_model
data_directory: ../
topology_file: Topology.txt
target_gmm_file: gmm_file_ouput.txt
emdb:
- em_map_mrc_id: Ciferri_CEM_PRC2.map.mrc
  gmm_map_approx: 50
  source_map_mrc_file: Ciferri_CEM_PRC2.map.mrc
  target_gmm_file: gmm_file_ouput.txt
  gmm_approx_mrc_file: Ciferri_CEM_PRC2.gmm50.mrc
- em_map_mrc_id: my_map.mrc
  gmm_map_approx: 50
  source_map_mrc_file: my_map.mrc
  target_gmm_file: my_map.gmm50.txt
  gmm_approx_mrc_file: my_map.gmm50.mrcudo cp /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum.tgz /home/ubuntu/notebooks

... additional lines ...


```






**Content of aws_run_onenode.sh for docker version**
```
#/usr/bin/bash -x
runnum=$1
# pip install awscli --upgrade --user

sudo mkdir /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum
sudo chmod 777 /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum
cd      /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum
sudo cp /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model/*.* /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum

# -n 16 is set to number of cores, 16 in this case; amend to 8 when on 8 cpu machine
sudo /shared/anaconda/bin/mpiexec -n 16 /shared/anaconda/bin/python prep_hyperp_imp_v2_14_0ux.py --count=1 --name=DemoImpModel --config=ConfigImp.yaml >/home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum/trace.log 2>&1

# steps to archive job run and make it available to copy to s3 bucket
cd      /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out
tar -cvzf imp_model$runnum.tgz /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum
sudo cp /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model$runnum.tgz /home/ubuntu/notebooks

```


The jcl_docker.sh script is added to the /shared/notebooks folder and is used to run the job from outside the container.


**Content of jcl_docker.sh for docker version**
```
#/usr/bin/bash -x
runnum=$1
# start the container
docker container ls -a
#docker container start a848d063379e
# outside the container 
docker exec a848d063379e sudo bash /home/ubuntu/notebooks/imp/imp_msstudio_init-master/mss_out/imp_model/aws_run_onenode.sh $runnum

# upon completion the tgz is copied to the notebooks folder and we can then simply action s3 cp 
#aws s3 cp imp_model$runnum.tgz s3://impmpi/imp_model_docker$runnum.tgz

#shutdown # this will terminate the aws EC2 instance that we have used to run the modelling job


```



The job has logging output to a trace.log and prep_hyperp_imp_v2_14_0ux.log  
prep_hyperp_imp_v2_14_0ux.py script has the actual modelling run enabled with the line 
* TODO TEST WITHOUT MODEL RUN* mc1.execute_macro()




**Content of example log file; prep_hyperp_imp_v2_14_0ux.log**
```
done EM setup
skip gemt addition: EM file does NOT exist ../data/em/my_map.gmm50.txt!
Setting up MonteCarlo
Setting up ReplicaExchange
ReplicaExchange: MPI was found. Using Parallel Replica Exchange
Setting up stat file
Setting up replica stat file
Setting up best pdb files
Setting up and writing initial rmf coordinate file
got existing rex object
Setting up production rmf files
ReplicaExchange0: it generates initial.*.rmf3, stat.*.out, rmfs/*.rmf3 for each replica 
--- it stores the best scoring pdb models in pdbs/
--- the stat.*.out and rmfs/*.rmf3 are saved only at the lowest temperature
--- variables:
------ atomistic                      False
------ best_pdb_dir                   pdbs/
------ best_pdb_name_suffix           model
------ do_clean_first                 True
------ do_create_directories          True
------ geometries                     None
------ global_output_directory        ./imp_model
------ initial_rmf_name_suffix        initial
------ molecular_dynamics_steps       10
------ monte_carlo_steps              10
------ monte_carlo_temperature        1.0
------ nframes_write_coordinates      1
------ num_sample_rounds              1
------ number_of_best_scoring_models  0
------ number_of_frames               200
------ number_of_states               1
------ replica_exchange_maximum_temperature 2.5
------ replica_exchange_minimum_temperature 1.0
------ replica_exchange_swap          True
------ replica_stat_file_suffix       stat_replica
------ rmf_dir                        rmfs/
------ save_coordinates_mode          lowest_temperature
------ self_adaptive                  False
------ simulated_annealing            True
------ simulated_annealing_maximum_temperature 2.5
------ simulated_annealing_maximum_temperature_nframes 20
------ simulated_annealing_minimum_temperature 1.0
------ simulated_annealing_minimum_temperature_nframes

```


The aws cli can be used to setup the EC2 instance



**The aws cli can be used to setup the EC2 instance**
```

# setup aws cli on windows
aws --version

#at anaconda prompt:
python -m pip install --upgrade pip

pip install --upgrade awscli
#Successfully installed awscli-1.16.277 botocore-1.13.13
# aws-cli/1.17.9 Python/3.7.3 Windows/10 botocore/1.14.9

```


**Content of anaimp_docker_launch_instance_config_v3c.json**
```
{
    "ImageId": "ami-0191299d04ce0bef0",
    "InstanceType": "t3a.2xlarge",
    "KeyName": "msstudio_org_kp",
    "SecurityGroupIds": [
        "sg-08139f017b4a5805e"
    ],
    "SubnetId": "subnet-1eb92835",
    "DisableApiTermination": false,
    "DryRun": false,
    "EbsOptimized": true,
    "IamInstanceProfile": {
        "Name": "s3_bld_rw_only"
    },
	"NetworkInterfaces": [
        {
            "AssociatePublicIpAddress": true,
            "DeleteOnTermination": true,
            "DeviceIndex": 0			
        }
    ],	
    "InstanceMarketOptions": {
        "MarketType": "spot",
        "SpotOptions": {
            "MaxPrice": "0.75",
            "SpotInstanceType": "one-time",
            "InstanceInterruptionBehavior": "terminate"
        }
    }
}

```





**AWS CLI call to EC2 create anaimp_docker_launch_instance_config_v3c.json**
```
aws ec2 run-instances --cli-input-json file://C:/dev/aws/aws_parallelcluster/anaimp_docker_launch_instance_config_v3c.json

# terminate with following commands; set params correctly
aws ec2 terminate-instances --instance-ids i-0382d549facbfbfd8

aws ec2 cancel-spot-instance-requests --spot-instance-request-ids sir-dajyamkp



```


That concludes the steps for setting up and running IMP on AWS using a docker image.

